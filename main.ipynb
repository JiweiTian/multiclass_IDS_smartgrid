{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset #1\n",
      "Loading dataset #2\n",
      "Finished Loading. Final Size = (10035, 129)\n"
     ]
    }
   ],
   "source": [
    "print('Loading dataset #1')\n",
    "data = pd.DataFrame(arff.loadarff('input/power_multiclass/data1.arff')[0])\n",
    "\n",
    "for i in range(2,3):\n",
    "    print('Loading dataset #{}'.format(i))\n",
    "    dataTemp = pd.DataFrame(arff.loadarff('input/power_multiclass/data{}.arff'.format(i))[0])\n",
    "    data = pd.concat([data,dataTemp],axis=0)\n",
    "\n",
    "print(\"Finished Loading. Final Size = {}\".format(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataProc(df):\n",
    "    '''\n",
    "    This function takes a dataframe and splits it into data and labels, proccesses them into numpy arrays and\n",
    "    splits them into training, validation, and testing data and labels.\n",
    "    '''\n",
    "    df = df.astype(np.float64)\n",
    "    label = df['marker'].astype(int)\n",
    "    df = df.drop(['marker'], axis=1)\n",
    "    \n",
    "    df = df.drop(['snort_log1','snort_log2','snort_log3','snort_log4',\n",
    "                'control_panel_log1','control_panel_log2','control_panel_log3','control_panel_log4',\n",
    "                'relay1_log','relay2_log','relay3_log','relay4_log'], axis=1)\n",
    "    \n",
    "    df = df.reset_index()\n",
    "    \n",
    "    df = df.replace(-np.inf, 0)\n",
    "    df = df.replace(np.inf, 0)\n",
    "\n",
    "    \n",
    "    # Converting to arrays\n",
    "    X = np.asarray(df)\n",
    "    y =  np.asarray(label)\n",
    "    \n",
    "    # Scaling data\n",
    "    scalar = preprocessing.MinMaxScaler()\n",
    "    X = scalar.fit_transform(X)\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X: (10035, 117)\n",
      "Size of y: (10035,)\n"
     ]
    }
   ],
   "source": [
    "X,y = dataProc(data)\n",
    "print('Size of X: {}'.format(X.shape))\n",
    "print('Size of y: {}'.format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import erlc\n",
    "\n",
    "model = erlc.ERLC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ERLC model\n",
      "Building autoencoder\n",
      "Epoch 1/2\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.0686 - mse: 0.0686 - val_loss: 0.0399 - val_mse: 0.0399\n",
      "Epoch 2/2\n",
      "26/26 [==============================] - 2s 71ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Getting new representation of the data\n",
      "Training DT on original representation\n",
      "Training DT on new representation\n",
      "Training RF on original representation\n",
      "Training RF on new representation\n",
      "Training inner DNN\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:Layer dense_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "201/201 [==============================] - 3s 17ms/step - loss: 3.1677 - val_loss: 2.5549\n",
      "Epoch 2/3\n",
      "201/201 [==============================] - 1s 7ms/step - loss: 2.2164 - val_loss: 1.9332\n",
      "Epoch 3/3\n",
      "201/201 [==============================] - 1s 7ms/step - loss: 1.8105 - val_loss: 1.6634\n",
      "WARNING:tensorflow:From /home/jacob/Projects/multiclass_IDS_smartgrid/erlc.py:76: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "Training inner DNN on new representation\n",
      "Epoch 1/3\n",
      "201/201 [==============================] - 2s 9ms/step - loss: 3.3257 - val_loss: 2.9029\n",
      "Epoch 2/3\n",
      "201/201 [==============================] - 2s 9ms/step - loss: 2.5218 - val_loss: 2.1829\n",
      "Epoch 3/3\n",
      "201/201 [==============================] - 2s 8ms/step - loss: 2.1162 - val_loss: 1.9586\n",
      "Epoch 1/2\n",
      "201/201 [==============================] - 3s 15ms/step - loss: 0.8507 - val_loss: 0.2055\n",
      "Epoch 2/2\n",
      "147/201 [====================>.........] - ETA: 0s - loss: 0.1570"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, sae_epochs = 2, outerNN_epochs = 2, innerNN_epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiclass_IDS_env",
   "language": "python",
   "name": "multiclass_ids_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
